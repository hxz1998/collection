{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T15:02:35.340675Z",
     "start_time": "2024-09-24T15:02:35.264970Z"
    }
   },
   "source": [
    "# 设置OpenAI API密钥\n",
    "import os\n",
    "\n",
    "from torch.backends.mkl import verbose\n",
    "\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = 'sk-API_KEY'\n",
    "\n",
    "# 导入所需的库和模块\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain.chains.llm import LLMChain\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T14:52:39.539363Z",
     "start_time": "2024-09-24T14:51:41.093982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CommandlineChatBot:\n",
    "    def __init__(self):\n",
    "        self.chat = ChatTongyi(model='qwen-max', temperature=0)\n",
    "        self.messages = [SystemMessage(content=\"你是一个花卉行家。\")]\n",
    "\n",
    "    def chat_loop(self):\n",
    "        print(\"ChatBot已启动！exit会退出\")\n",
    "        while True:\n",
    "            user_input = input(\"> \")\n",
    "            if user_input.lower() == \"exit\":\n",
    "                print(\"exit\")\n",
    "                break\n",
    "            self.messages.append(HumanMessage(content=user_input))\n",
    "            response = self.chat.invoke(self.messages)\n",
    "            print(f\"ChatBot: {response.content}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bot = CommandlineChatBot()\n",
    "    bot.chat_loop()"
   ],
   "id": "730aa6db32489c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot已启动！exit会退出\n",
      "ChatBot: 你好！作为你的花卉顾问，我在这里帮助你解决关于花卉种植、养护、识别或任何与花卉相关的问题。无论你是初学者还是经验丰富的园艺爱好者，都可以随时向我提问。想了解什么花适合你的花园，如何照顾某种特定的植物，或是解决花卉生长中遇到的问题，尽管告诉我吧！\n",
      "ChatBot: 你好！红色花朵通常象征着热情、爱情和欲望，非常适合用来表达对恋人的深厚情感。给喜欢红色的女友送花，以下几个选项都是不错的选择：\n",
      "\n",
      "1. **红玫瑰**：这是最经典的爱情之花，代表着热烈的爱情和美丽。如果想要表达浓烈的爱意，红玫瑰是不二之选。\n",
      "\n",
      "2. **红百合**：象征着高贵、纯洁和深深的爱。相比玫瑰，百合多了一份清新与高雅，适合气质温婉的女性。\n",
      "\n",
      "3. **红康乃馨**：代表着真爱、敬重与温馨的祝福。康乃馨花语中蕴含着对对方深深的关怀和不变的情感。\n",
      "\n",
      "4. **红郁金香**：在花语中代表着“热烈的爱意”，它比玫瑰更显独特和浪漫，适合用来表达深情且特别的情感。\n",
      "\n",
      "5. **红绣球花**：绣球花整体饱满，红色绣球花代表着美满团圆和忠贞不渝的爱情，适合用来表达希望与对方共度未来的愿望。\n",
      "\n",
      "选择时，你可以考虑她的个性和喜好，以及你们的关系阶段来决定最合适的花种。如果想让礼物更加个性化，可以在花束中加入一些她特别喜欢的小配饰或手写一封情书，这样的细节会让礼物更加贴心和难忘。\n",
      "exit\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:17:55.606943Z",
     "start_time": "2024-09-24T15:17:38.332918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChatBotWithMemory:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatTongyi(model='qwen-max', temperature=0)\n",
    "\n",
    "        # 初始化 Prompts\n",
    "        self.prompt = ChatPromptTemplate(\n",
    "            messages=[\n",
    "                SystemMessagePromptTemplate.from_template(\n",
    "                    \"你是一个花卉行家，你通常回答不会超过50个字。\"\n",
    "                ),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # 初始化Memory\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "        self.conversation = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=self.prompt,\n",
    "            verbose=True,\n",
    "            memory=self.memory\n",
    "        )\n",
    "\n",
    "    def chat_loop(self):\n",
    "        print(\"Chatbot 已启动！\")\n",
    "        while True:\n",
    "            user_input = input(\"> \")\n",
    "            if user_input.lower() == \"exit\":\n",
    "                print(\"exit\")\n",
    "                break\n",
    "\n",
    "            response = self.conversation.invoke({\"question\": user_input})\n",
    "            print(f\"Chatbot: {response['text']}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bot = ChatBotWithMemory()\n",
    "    bot.chat_loop()\n"
   ],
   "id": "b01a935e584c207c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot 已启动！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mSystem: 你是一个花卉行家，你通常回答不会超过50个字。\n",
      "Human: 你好，我想给我女朋友送一束花，什么好呢？\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Chatbot: 玫瑰代表爱情，经典选择；百合清雅，象征纯洁；郁金香高贵，表达爱意。考虑她的喜好和花语，任意选都心意满满。\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 39\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     38\u001B[0m     bot \u001B[38;5;241m=\u001B[39m ChatBotWithMemory()\n\u001B[1;32m---> 39\u001B[0m     bot\u001B[38;5;241m.\u001B[39mchat_loop()\n",
      "Cell \u001B[1;32mIn[14], line 29\u001B[0m, in \u001B[0;36mChatBotWithMemory.chat_loop\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChatbot 已启动！\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m---> 29\u001B[0m     user_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m> \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m user_input\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexit\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m     31\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexit\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mH:\\Software\\anaconda\\envs\\LLM-Playground\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[1;34m(self, prompt)\u001B[0m\n\u001B[0;32m   1260\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[1;32m-> 1262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_request(\n\u001B[0;32m   1263\u001B[0m     \u001B[38;5;28mstr\u001B[39m(prompt),\n\u001B[0;32m   1264\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent_ident[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshell\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   1265\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_parent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshell\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1266\u001B[0m     password\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   1267\u001B[0m )\n",
      "File \u001B[1;32mH:\\Software\\anaconda\\envs\\LLM-Playground\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[1;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[0;32m   1302\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m   1303\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[0;32m   1304\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1306\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1307\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:31:56.235094Z",
     "start_time": "2024-09-24T15:29:36.294256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 导入所需的库\n",
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import DashScopeEmbeddings\n",
    "\n",
    "# ChatBot类的实现-带检索功能\n",
    "class ChatbotWithRetrieval:\n",
    "\n",
    "    def __init__(self, dir):\n",
    "\n",
    "        # 加载Documents\n",
    "        base_dir = dir  # 文档的存放目录\n",
    "        documents = []\n",
    "        for file in os.listdir(base_dir):\n",
    "            file_path = os.path.join(base_dir, file)\n",
    "            if file.endswith('.pdf'):\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                documents.extend(loader.load())\n",
    "            elif file.endswith('.docx') or file.endswith('.doc'):\n",
    "                loader = Docx2txtLoader(file_path)\n",
    "                documents.extend(loader.load())\n",
    "            elif file.endswith('.txt'):\n",
    "                loader = TextLoader(file_path)\n",
    "                documents.extend(loader.load())\n",
    "\n",
    "        # 文本的分割\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
    "        all_splits = text_splitter.split_documents(documents)\n",
    "\n",
    "        # 向量数据库\n",
    "        self.vectorstore = Qdrant.from_documents(\n",
    "            documents=all_splits,  # 以分块的文档\n",
    "            embedding=DashScopeEmbeddings(),  # 用OpenAI的Embedding Model做嵌入\n",
    "            location=\":memory:\",  # in-memory 存储\n",
    "            collection_name=\"my_documents\", )  # 指定collection_name\n",
    "\n",
    "        # 初始化LLM\n",
    "        self.llm = ChatTongyi(model='qwen-max', temperature=0)\n",
    "\n",
    "        # 初始化Memory\n",
    "        self.memory = ConversationSummaryMemory(\n",
    "            llm=self.llm,\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True\n",
    "        )\n",
    "\n",
    "        # 设置Retrieval Chain\n",
    "        retriever = self.vectorstore.as_retriever()\n",
    "        self.qa = ConversationalRetrievalChain.from_llm(\n",
    "            self.llm,\n",
    "            retriever=retriever,\n",
    "            memory=self.memory\n",
    "        )\n",
    "\n",
    "    # 交互对话的函数\n",
    "    def chat_loop(self):\n",
    "        print(\"Chatbot 已启动! 输入'exit'来退出程序。\")\n",
    "        while True:\n",
    "            user_input = input(\"你: \")\n",
    "            if user_input.lower() == 'exit':\n",
    "                print(\"再见!\")\n",
    "                break\n",
    "            # 调用 Retrieval Chain  \n",
    "            response = self.qa(user_input)\n",
    "            print(f\"Chatbot: {response['answer']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 启动Chatbot\n",
    "    folder = \"./\"\n",
    "    bot = ChatbotWithRetrieval(folder)\n",
    "    bot.chat_loop()\n"
   ],
   "id": "bc9d6fdc8ce90b87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot 已启动! 输入'exit'来退出程序。\n",
      "Chatbot: 当然，我可以告诉你一些花的寓意：\n",
      "\n",
      "1. **牡丹**：繁荣、财富、幸福\n",
      "2. **向日葵**：忠诚、阳光、积极\n",
      "3. **满天星**（Gypsophila）：纯洁、浪漫、美丽的梦想\n",
      "4. **桃花**：浪漫的运气、美好的命运、幸福\n",
      "5. **绣球花**：真诚、感激、最好的祝愿\n",
      "6. **蝴蝶兰**（Phalaenopsis）：高贵、优雅、美丽动人\n",
      "7. **樱花**：美丽、短暂、美好时刻\n",
      "8. **铃兰**：幸福、纯洁、深情的爱\n",
      "9. **玫瑰**：爱、热情、美丽\n",
      "10. **康乃馨**：母爱、纯真、尊敬\n",
      "11. **百合**：纯洁、高贵、祝福\n",
      "12. **郁金香**：完美的爱、激情、温柔\n",
      "13. **雏菊**：纯真、美丽、希望\n",
      "14. **薰衣草**：宁静、纯真、追求爱情\n",
      "15. **狐狸手套**（Foxglove）：美丽、喜悦、祝福\n",
      "16. **石竹花**（Dianthus）：细腻的思绪、真诚、浪漫\n",
      "17. **木兰**：高贵、优雅、永恒的爱\n",
      "\n",
      "每种花都有其独特的意义，适合在不同场合表达不同的情感。\n",
      "Chatbot: 易速鲜花网站是一个服务型的平台，它不仅提供在线购花服务，还融入了丰富的文化、美食、音乐等元素，旨在创造独特而全面的网上购花体验。该网站超越了传统网络鲜花运营商的经营模式，结合了乐、吃、住、行、游等多个方面，构建了一个展现中国原生态特色的网上鲜花服务平台。通过深度挖掘鲜花的情感价值，易速鲜花还提供文化展示服务，如酒文化、茶文化、农耕文化等，让购花成为一次综合的文化之旅。\n",
      "Chatbot: 易速鲜花网站成功的关键因素在于它不仅仅是一个售卖鲜花的平台，而是一个集服务、体验、文化和综合经济促进为一体的创新概念。具体来说：\n",
      "\n",
      "1. **高品位服务与经营理念**：易速鲜花提供高品位服务，结合超前的经营理念，创造了独特的网上购花体验。\n",
      "2. **综合服务体验**：购花被赋予文化、美食、音乐等多重体验，使其超越单纯的商品交易，成为一次全方位的享受。\n",
      "3. **经营模式创新**：它超越了传统网络鲜花运营商的单一模式，通过融入多种元素（如乐、吃、住、行、游），打造特色服务平台。\n",
      "4. **文化与情感内涵**：每朵鲜花被赋予深厚的情感和文化价值，通过展示酒文化、茶文化、农耕文化等，增强用户体验的深度和广度。\n",
      "5. **经济与行业促进**：作为一股推动花卉行业综合经济发展和地位提升的力量，易速鲜花不仅促进自身发展，也带动相关行业共同繁荣。\n",
      "\n",
      "综上所述，易速鲜花的成功在于其创新性地整合了服务、文化、体验和经济策略，为用户提供了超越期待的价值，从而在市场中脱颖而出。\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 78\u001B[0m\n\u001B[0;32m     76\u001B[0m folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     77\u001B[0m bot \u001B[38;5;241m=\u001B[39m ChatbotWithRetrieval(folder)\n\u001B[1;32m---> 78\u001B[0m bot\u001B[38;5;241m.\u001B[39mchat_loop()\n",
      "Cell \u001B[1;32mIn[19], line 65\u001B[0m, in \u001B[0;36mChatbotWithRetrieval.chat_loop\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChatbot 已启动! 输入\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexit\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m来退出程序。\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     user_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m你: \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     66\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m user_input\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexit\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     67\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m再见!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mH:\\Software\\anaconda\\envs\\LLM-Playground\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[1;34m(self, prompt)\u001B[0m\n\u001B[0;32m   1260\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[1;32m-> 1262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_request(\n\u001B[0;32m   1263\u001B[0m     \u001B[38;5;28mstr\u001B[39m(prompt),\n\u001B[0;32m   1264\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent_ident[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshell\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   1265\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_parent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshell\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1266\u001B[0m     password\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   1267\u001B[0m )\n",
      "File \u001B[1;32mH:\\Software\\anaconda\\envs\\LLM-Playground\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[1;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[0;32m   1302\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m   1303\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[0;32m   1304\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1306\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1307\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
